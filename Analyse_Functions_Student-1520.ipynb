{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analyse_Functions_Student.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91yHydRjEmqq",
        "colab_type": "text"
      },
      "source": [
        "# Analyse : Predict\n",
        "\n",
        "Functions are important in reducing the replication of code as well as giving the user the functionality of getting an ouput on varying inputs. The functions you will write all use Eskom data/variables.\n",
        "\n",
        "For the predict, you will need to write 7 functions. These functions are:\n",
        "\n",
        "1. Metric Dictionary\n",
        "2. Five Number Summary Dictionary\n",
        "3. Date Parser\n",
        "4. Hashtag & Municipality Remover\n",
        "5. Number of Tweets per Day\n",
        "6. Word Splitter\n",
        "7. Stopwords & Link Remover\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmw-PmDMOPyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS-1DpWNOUaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/RidhaMoosa/eskom_data-/master/electrification_by_province.csv'\n",
        "ebp = pd.read_csv(url)\n",
        "\n",
        "for col, row in ebp.iloc[:,1:].iteritems():\n",
        "    ebp[col] = ebp[col].str.replace(',','').astype(int)\n",
        "\n",
        "limpopo = ebp['Limpopo'].to_list()\n",
        "limpopo = [float(x) for x in limpopo]\n",
        "\n",
        "mpumalanga = ebp['Mpumalanga'].to_list()\n",
        "mpumalanga = [float(x) for x in mpumalanga]\n",
        "\n",
        "north_west = ebp['North west'].to_list()\n",
        "north_west = [float(x) for x in north_west]\n",
        "\n",
        "free_state = ebp['Free State'].to_list()\n",
        "free_state = [float(x) for x in free_state]\n",
        "\n",
        "kwazulu_natal = ebp['Kwazulu Natal'].to_list()\n",
        "kwazulu_natal = [float(x) for x in kwazulu_natal]\n",
        "\n",
        "eastern_cape = ebp['Eastern Cape'].to_list()\n",
        "eastern_cape = [float(x) for x in eastern_cape]\n",
        "\n",
        "western_cape = ebp['Western Cape'].to_list()\n",
        "western_cape = [float(x) for x in western_cape]\n",
        "\n",
        "northern_cape = ebp['Northern Cape'].to_list()\n",
        "northern_cape = [float(x) for x in northern_cape]\n",
        "\n",
        "gauteng = ebp['Gauteng'].to_list()\n",
        "gauteng = [float(x) for x in gauteng]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkUMnbVNOfu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/RidhaMoosa/eskom_data-/master/twitter_nov_2019.csv'\n",
        "twitter_df = pd.read_csv(url)\n",
        "\n",
        "dates = twitter_df['Date'].to_list()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQL8b34-HThO",
        "colab_type": "text"
      },
      "source": [
        "# Function 1: Metric Dictionary\n",
        "\n",
        "Write a function which takes in a list of integers and returns a dictionary of the mean, median, variance, standard deviation, min and max. Answers should be rounded to the second decimal.\n",
        "\n",
        "_**Expected Output**_:\n",
        "\n",
        "```python\n",
        "gauteng = [39660.0,\n",
        "            36024.0,\n",
        "            32127.0,\n",
        "            39488.0,\n",
        "            18422.0,\n",
        "            23532.0,\n",
        "            8842.0,\n",
        "            37416.0,\n",
        "            16156.0,\n",
        "            18730.0,\n",
        "            19261.0,\n",
        "            25275.0]\n",
        "\n",
        "dictionary_of_metrics(gauteng) == {'mean': 26244.42,\n",
        "                                   'median': 24403.5,\n",
        "                                   'variance': 108160153.17,\n",
        "                                   'standard deviation': 10400.01,\n",
        "                                   'min': 8842.0,\n",
        "                                   'max': 39660.0}\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-2fY34IHQwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dictionary_of_metrics(items):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQIz0kjeJYYi",
        "colab_type": "text"
      },
      "source": [
        "# Function 2: Five Number Summary\n",
        "\n",
        "Write a function which takes in a list of integers and returns a dictionary of the [five number summary.](https://www.statisticshowto.datasciencecentral.com/how-to-find-a-five-number-summary-in-statistics/) Answers should be rounded to the nearest second decimal.\n",
        "\n",
        "_**Expected Output:**_\n",
        "\n",
        "```python\n",
        "\n",
        "gauteng = [39660.0,\n",
        "            36024.0,\n",
        "            32127.0,\n",
        "            39488.0,\n",
        "            18422.0,\n",
        "            23532.0,\n",
        "            8842.0,\n",
        "            37416.0,\n",
        "            16156.0,\n",
        "            18730.0,\n",
        "            19261.0,\n",
        "            25275.0]\n",
        "\n",
        "five_num_summ(gauteng) == {'max': 39660.0,\n",
        "                           'median': 24403.5,\n",
        "                           'min': 8842.0,\n",
        "                           'q1': 18422.5,\n",
        "                           'q3': 36024.5}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZUUmnL1JWFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def five_num_summ(items):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETAOSB2oP9-Z",
        "colab_type": "text"
      },
      "source": [
        "# Function 3: Date Parser\n",
        "\n",
        "Write a function which takes a list of datetime strings and converts it into a list of strings with only the date. \n",
        "<br>\n",
        "<br>\n",
        "_**Expected Output:**_\n",
        "\n",
        "```python\n",
        "\n",
        "dates = ['2019-11-29 12:50:54',\n",
        "         '2019-11-29 12:46:53',\n",
        "         '2019-11-29 12:46:10',\n",
        "         '2019-11-29 12:33:36',\n",
        "         '2019-11-29 12:17:43',\n",
        "         '2019-11-29 11:28:40']\n",
        "\n",
        "date_parser(dates) == ['2019-11-29',\n",
        "                       '2019-11-29',\n",
        "                       '2019-11-29',\n",
        "                       '2019-11-29',\n",
        "                       '2019-11-29',\n",
        "                       '2019-11-29']\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IA0CkEJNW_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def date_parser(list_dates):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2GhFqo4SvD2",
        "colab_type": "text"
      },
      "source": [
        "# Function 4: Municipality & Hashtag Remover\n",
        "\n",
        "Write a function which takes in a pandas dataframe and returns the same dataframe which is modified. The function should do the following:\n",
        "\n",
        "* Extract the municipality from a tweet using the dictonary given below into a new column in the same dataframe.\n",
        "* Extract the hashtag from a tweet into a new column in the same data frame.\n",
        "* The column headers should be \"municipality\" & \"hashtags\" respectively.\n",
        "* For those tweets which don't have the either a municipality nor a hashtag, fill it with ```np.nan```.\n",
        "\n",
        "Note: Only pandas and numpy packages may be used.\n",
        "\n",
        "```python\n",
        "\n",
        "municipality_dict = { '@CityofCTAlerts' : 'Cape Town',\n",
        "            '@CityPowerJhb' : 'Johannesburg',\n",
        "            '@eThekwiniM' : 'eThekwini' ,\n",
        "            '@EMMInfo' : 'Ekurhuleni',\n",
        "            '@centlecutility' : 'Mangaung',\n",
        "            '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
        "            '@CityTshwane' : 'Tshwane'}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErK3jHb5W8dE",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_ \n",
        "\n",
        "```python\n",
        "\n",
        "extract_municipality_hashtags(twitter_df).iloc[:11, :10]\n",
        "\n",
        "```\n",
        "![image](https://github.com/RidhaMoosa/eskom_data-/blob/master/function4.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TEUIY_qCSYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_municipality_hashtags(df):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSuzSIc7_VUh",
        "colab_type": "text"
      },
      "source": [
        "# Function 5: Number of Tweets per Day\n",
        "\n",
        "Write a function which calculates the number of tweets that were posted per day. \n",
        "\n",
        "This function should take in a pandas dataframe and return a new dataframe with columns \"```Date```\" & \"```Number of Tweets```\"\n",
        "\n",
        "Note: Only pandas and numpy may be used.\n",
        "\n",
        "_**Expected Output:**_\n",
        "\n",
        "```python\n",
        "\n",
        "number_of_tweets_per_day(twitter_df)\n",
        "\n",
        "```\n",
        "\n",
        "![function5](https://github.com/RidhaMoosa/eskom_data-/blob/master/function5.png?raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Vo6QoAW6nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def number_of_tweets_per_day(df):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wye_CrLFSgS",
        "colab_type": "text"
      },
      "source": [
        "# Function 6: Word Splitter\n",
        "\n",
        "Write a function which splits a sentence into a list of the separate words. This is also known as [tokenization](https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/).\n",
        "\n",
        "The function should take in a dataframe and return a data with a new column \"```Split Tweets```\". Words should also all be lowercase.\n",
        "\n",
        "Note: Only pandas and numpy packages may be used.\n",
        "<br>\n",
        "<br>\n",
        "_**Expected Output**_:\n",
        "\n",
        "```python\n",
        "\n",
        "word_spliter(twitter_df) \n",
        "\n",
        "```\n",
        "\n",
        "![Function6](https://github.com/RidhaMoosa/eskom_data-/blob/master/Function6.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmEE1Zu7IrPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_spliter(df):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsCMKM0KKRsb",
        "colab_type": "text"
      },
      "source": [
        "# Function 7: Stop Words & Link Remover\n",
        "\n",
        "Write a function which removes the stop words and the ur link from a tweet. The function should follow the criteria below:\n",
        "\n",
        "* Should remove stop words based on the dictionary provided below.\n",
        "* Should remove url's from the tweets. \n",
        "* The function will also need to tokenise thee sentence as indicated in function 6. Note: Function 6 may not be called within this function.\n",
        "* The column should be labelled as \"```Without Stop Words```\"\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "```python \n",
        "stop_words_dict = {'stopwords':['where', 'done', 'if', 'before', 'll', 'very', 'keep', 'something', 'nothing', 'thereupon', 'may', 'why', '’s', 'therefore', 'you', 'with', 'towards', 'make', 'really', 'few', 'former', 'during', 'mine', 'do', 'would', 'of', 'off', 'six', 'yourself', 'becoming', 'through', 'seeming', 'hence', 'us', 'anywhere', 'regarding', 'whole', 'down', 'seem', 'whereas', 'to', 'their', 'various', 'thereafter', '‘d', 'above', 'put', 'sometime', 'moreover', 'whoever', 'although', 'at', 'four', 'each', 'among', 'whatever', 'any', 'anyhow', 'herein', 'become', 'last', 'between', 'still', 'was', 'almost', 'twelve', 'used', 'who', 'go', 'not', 'enough', 'well', '’ve', 'might', 'see', 'whose', 'everywhere', 'yourselves', 'across', 'myself', 'further', 'did', 'then', 'is', 'except', 'up', 'take', 'became', 'however', 'many', 'thence', 'onto', '‘m', 'my', 'own', 'must', 'wherein', 'elsewhere', 'behind', 'becomes', 'alone', 'due', 'being', 'neither', 'a', 'over', 'beside', 'fifteen', 'meanwhile', 'upon', 'next', 'forty', 'what', 'less', 'and', 'please', 'toward', 'about', 'below', 'hereafter', 'whether', 'yet', 'nor', 'against', 'whereupon', 'top', 'first', 'three', 'show', 'per', 'five', 'two', 'ourselves', 'whenever', 'get', 'thereby', 'noone', 'had', 'now', 'everyone', 'everything', 'nowhere', 'ca', 'though', 'least', 'so', 'both', 'otherwise', 'whereby', 'unless', 'somewhere', 'give', 'formerly', '’d', 'under', 'while', 'empty', 'doing', 'besides', 'thus', 'this', 'anyone', 'its', 'after', 'bottom', 'call', 'n’t', 'name', 'even', 'eleven', 'by', 'from', 'when', 'or', 'anyway', 'how', 'the', 'all', 'much', 'another', 'since', 'hundred', 'serious', '‘ve', 'ever', 'out', 'full', 'themselves', 'been', 'in', \"'d\", 'wherever', 'part', 'someone', 'therein', 'can', 'seemed', 'hereby', 'others', \"'s\", \"'re\", 'most', 'one', \"n't\", 'into', 'some', 'will', 'these', 'twenty', 'here', 'as', 'nobody', 'also', 'along', 'than', 'anything', 'he', 'there', 'does', 'we', '’ll', 'latterly', 'are', 'ten', 'hers', 'should', 'they', '‘s', 'either', 'am', 'be', 'perhaps', '’re', 'only', 'namely', 'sixty', 'made', \"'m\", 'always', 'those', 'have', 'again', 'her', 'once', 'ours', 'herself', 'else', 'has', 'nine', 'more', 'sometimes', 'your', 'yours', 'that', 'around', 'his', 'indeed', 'mostly', 'cannot', '‘ll', 'too', 'seems', '’m', 'himself', 'latter', 'whither', 'amount', 'other', 'nevertheless', 'whom', 'for', 'somehow', 'beforehand', 'just', 'an', 'beyond', 'amongst', 'none', \"'ve\", 'say', 'via', 'but', 'often', 're', 'our', 'because', 'rather', 'using', 'without', 'throughout', 'on', 'she', 'never', 'eight', 'no', 'hereupon', 'them', 'whereafter', 'quite', 'which', 'move', 'thru', 'until', 'afterwards', 'fifty', 'i', 'itself', 'n‘t', 'him', 'could', 'front', 'within', '‘re', 'back', 'such', 'already', 'several', 'side', 'whence', 'me', 'same', 'were', 'it', 'every', 'third', 'together']}\n",
        "```\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "_**Expected Output**_:\n",
        "\n",
        "```python\n",
        "stop_words_http_remover(twitter_df)\n",
        "```\n",
        "\n",
        "![function7](https://github.com/RidhaMoosa/eskom_data-/blob/master/Function7.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7IHGYFtW5HJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stop_words_http_remover(df):\n",
        "\n",
        "  # Code Here\n",
        "\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}