{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eskom_Analyse_functions_draft.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zVbVIfYheZP2",
        "0FCCWRFxe8VM",
        "W08cye-E78iH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVbVIfYheZP2",
        "colab_type": "text"
      },
      "source": [
        "# Importinng Modules and loading data from the csv file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqUpMH6udmMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xKzlSnieN0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/RidhaMoosa/eskom_data-/master/electrification_by_province.csv'\n",
        "ebp = pd.read_csv(url)\n",
        "\n",
        "for col, row in ebp.iloc[:,1:].iteritems():\n",
        "    ebp[col] = ebp[col].str.replace(',','').astype(int)\n",
        "\n",
        "limpopo = ebp['Limpopo'].to_list()\n",
        "limpopo = [float(x) for x in limpopo]\n",
        "\n",
        "mpumalanga = ebp['Mpumalanga'].to_list()\n",
        "mpumalanga = [float(x) for x in mpumalanga]\n",
        "\n",
        "north_west = ebp['North west'].to_list()\n",
        "north_west = [float(x) for x in north_west]\n",
        "\n",
        "free_state = ebp['Free State'].to_list()\n",
        "free_state = [float(x) for x in free_state]\n",
        "\n",
        "kwazulu_natal = ebp['Kwazulu Natal'].to_list()\n",
        "kwazulu_natal = [float(x) for x in kwazulu_natal]\n",
        "\n",
        "eastern_cape = ebp['Eastern Cape'].to_list()\n",
        "eastern_cape = [float(x) for x in eastern_cape]\n",
        "\n",
        "western_cape = ebp['Western Cape'].to_list()\n",
        "western_cape = [float(x) for x in western_cape]\n",
        "\n",
        "northern_cape = ebp['Northern Cape'].to_list()\n",
        "northern_cape = [float(x) for x in northern_cape]\n",
        "\n",
        "gauteng = ebp['Gauteng'].to_list()\n",
        "gauteng = [float(x) for x in gauteng]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO2WAeVZe6wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/RidhaMoosa/eskom_data-/master/twitter_nov_2019.csv'\n",
        "twitter_df = pd.read_csv(url)\n",
        "\n",
        "dates = twitter_df['Date'].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXM5zu8XCmbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "municipality_dict = { '@CityofCTAlerts' : 'Cape Town',\n",
        "            '@CityPowerJhb' : 'Johannesburg',\n",
        "            '@eThekwiniM' : 'eThekwini' ,\n",
        "            '@EMMInfo' : 'Ekurhuleni',\n",
        "            '@centlecutility' : 'Mangaung',\n",
        "            '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
        "            '@CityTshwane' : 'Tshwane'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3c7GE8VAe5C",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FCCWRFxe8VM",
        "colab_type": "text"
      },
      "source": [
        "# Function 3: Date Parser\n",
        "\n",
        "Write a function which takes a **list of datetime strings** and converts it into a **list of strings with only the date**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlQ4ErmFfA83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def date_parser(list_dates):\n",
        "    \"\"\"date_parser(list_dates)\n",
        "\n",
        "      Return a list of Date strings.\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      (list): list of datetime strings (REQUIRED)\n",
        "      \n",
        "      Return\n",
        "      ------\n",
        "      (list): list of Date strings.\n",
        "      \n",
        "      Examples\n",
        "      -------\n",
        "      >>>dates = ['2019-11-29 12:50:54',\n",
        "         '2019-11-29 12:46:53',\n",
        "         '2019-11-29 12:46:10',\n",
        "         '2019-11-29 12:33:36',\n",
        "         '2019-11-29 12:17:43',\n",
        "         '2019-11-29 11:28:40']\n",
        "\n",
        "      >>>date_parser(dates)\n",
        "      >>>['2019-11-29',\n",
        "          '2019-11-29',\n",
        "          '2019-11-29',\n",
        "          '2019-11-29',\n",
        "          '2019-11-29',\n",
        "          '2019-11-29']\n",
        "    \"\"\"\n",
        "    return [datetime.split()[0] for datetime in list_dates]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQTOGzLV0-6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee857071-489b-4810-a028-b04f51a1426d"
      },
      "source": [
        "date_parser(dates)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-29',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-28',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-27',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-26',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-25',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-24',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-23',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-22',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-21',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20',\n",
              " '2019-11-20']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W08cye-E78iH",
        "colab_type": "text"
      },
      "source": [
        "# Function 1: Metric Dictionary\n",
        "\n",
        "Write a function which takes in a list of integers and returns a dictionary of the mean, median, variance, standard deviation, min and max. Answers should be rounded to the second decimal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04Yul5i08McL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dictionary_of_metrics(items: list ,precision: int = 2):\n",
        "  lenght =len(items)\n",
        "  items.sort()\n",
        "  mean = (sum(items)/lenght)\n",
        "  #variance =sum((item - mean)**2 for item in items)/(lenght-1)\n",
        "  #standard_deviation = (sum((item - mean)**2 for item in items)/(lenght-1))**0.5\n",
        "  #median = (items[lenght//2] + items[lenght//2 - 1])/2 if lenght % 2 ==0  else items[lenght//2]\n",
        "  return {'Mean': round(mean,precision),\n",
        "          'median': round((items[lenght//2] + items[lenght//2 - 1])/2 if lenght % 2 ==0  else items[lenght//2],precision),\n",
        "          'variance': round(sum((item - (sum(items)/lenght))**2 for item in items)/(lenght-1),precision),\n",
        "          'standard deviation': round((sum((item - mean)**2 for item in items)/(lenght-1))**0.5,precision),\n",
        "          'min': round(min(items),precision),\n",
        "          'max': round(max(items),precision),\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBDttQVc-PYu",
        "colab_type": "code",
        "outputId": "ca8265e8-f08e-4f7d-e49e-b8994535ddf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        " dictionary_of_metrics(gauteng)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Mean': 26244.42,\n",
              " 'max': 39660.0,\n",
              " 'median': 24403.5,\n",
              " 'min': 8842.0,\n",
              " 'standard deviation': 10400.01,\n",
              " 'variance': 108160153.17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFzsTuwIAj7a",
        "colab_type": "text"
      },
      "source": [
        "# Function 4: Municipality & Hashtag Remover\n",
        "\n",
        "Write a function which takes in a pandas dataframe and returns the same dataframe which is modified. The function should do the following:\n",
        "\n",
        "Extract the municipality from a tweet using the dictonary given below into a new column in the same dataframe.\n",
        "Extract the hashtag from a tweet into a new column in the same data frame.\n",
        "The column headers should be \"municipality\" & \"hashtags\" respectively.\n",
        "For those tweets which don't have the either a municipality nor a hashtag, fill it with np.nan.\n",
        "Note: Only pandas and numpy packages may be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m7K5Fm8A-J-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_municipality_hashtags(df):\n",
        "\n",
        "  #----------municipality_match function--------\n",
        "  def municipality_match(string_from_series):\n",
        "    municipality = np.nan     #declearing and assigning the municipality list with nan from np.nan\n",
        "    for dic_key in municipality_dict:               #looping through the municipality_dict dictionary and grabing one key at a time.\n",
        "      if dic_key in string_from_series:             #checking if the dictionary key is in or contained within the string_from_series from the pandas series of tweets.\n",
        "          municipality = municipality_dict[dic_key] #loading/ appending the municipality with the value from the dictionary corresponding with the key.\n",
        "          break                                     #Breaking the loop if one municipality matched or detected. \n",
        "    return municipality                             #Returning the resulting list of municipalities per tweet\n",
        "\n",
        "  #----------hashtags_match function--------\n",
        "  def hashtags_match(string_from_series):\n",
        "      hashtags = []         #declearing an empty list to store the hashtags\n",
        "      for word in string_from_series.split(' '): # spliting the received string into a list of words and looping from the list to access each word at the time!\n",
        "        if word.startswith('#'):        #checking if the retrieved word starts with a #\n",
        "            hashtags.append(word)       #Appending the word(hashtag) into the list hashtags \n",
        "\n",
        "      if len(hashtags) != 0: #Checking if the hashtags list is  Empty\n",
        "          return hashtags    #Returning the hashtags list and exiting the hashtags_match function\n",
        "      else:\n",
        "          hashtags =np.nan   #if the hashtags list is  Empty, we assign a nan value from the numpy library!\n",
        "      return hashtags\n",
        "\n",
        "  #--------Calling and using the two functions to modify the Dataframe---------\n",
        "  df['municipality'] = df['Tweets'].apply(municipality_match)       #Calling the municipality_match function using the pandas series method apply() to modify by creating the municipality column.  \n",
        "  df['hashtags'] = df['Tweets'].apply(hashtags_match)         #Calling the hashtags_match function using the pandas series method apply() to modify by creating the hashtags column. \n",
        "  #-------------\n",
        "  return df     #returnig the resulting dataframe with all the changes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxRHjnDkCKKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "9a7a920c-0ab6-4ac5-913c-00a273906cd1"
      },
      "source": [
        "extract_municipality_hashtags(twitter_df).iloc[:11, :10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Date</th>\n",
              "      <th>municipality</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@BongaDlulane Please send an email to mediades...</td>\n",
              "      <td>2019-11-29 12:50:54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n",
              "      <td>2019-11-29 12:46:53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@BongaDlulane Query escalated to media desk.</td>\n",
              "      <td>2019-11-29 12:46:10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Before leaving the office this afternoon, head...</td>\n",
              "      <td>2019-11-29 12:33:36</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n",
              "      <td>2019-11-29 12:17:43</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[#ESKOMFREESTATE, #MEDIASTATEMENT]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@IamGladstone @CityPowerJhb @HermanMashaba The...</td>\n",
              "      <td>2019-11-29 11:28:40</td>\n",
              "      <td>Johannesburg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RT @Exposcience: #FridayMotivation #EskomExpoI...</td>\n",
              "      <td>2019-11-29 11:27:56</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[#FridayMotivation, #EskomExpoISF]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#EskomMpumalanga hosted a Supplier Development...</td>\n",
              "      <td>2019-11-29 11:07:18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[#EskomMpumalanga]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@maxon_hadebe @CityofJoburgZA Please log a cal...</td>\n",
              "      <td>2019-11-29 09:12:47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@Magudulela_M Hi,  Please log a call on MyEsko...</td>\n",
              "      <td>2019-11-29 09:08:33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RT @Exposcience: #FridayThoughts Norman Mashir...</td>\n",
              "      <td>2019-11-29 09:08:12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[#FridayThoughts]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweets  ...                            hashtags\n",
              "0   @BongaDlulane Please send an email to mediades...  ...                                 NaN\n",
              "1          @saucy_mamiie Pls log a call on 0860037566  ...                                 NaN\n",
              "2        @BongaDlulane Query escalated to media desk.  ...                                 NaN\n",
              "3   Before leaving the office this afternoon, head...  ...                                 NaN\n",
              "4   #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  ...  [#ESKOMFREESTATE, #MEDIASTATEMENT]\n",
              "5   @IamGladstone @CityPowerJhb @HermanMashaba The...  ...                                 NaN\n",
              "6   RT @Exposcience: #FridayMotivation #EskomExpoI...  ...  [#FridayMotivation, #EskomExpoISF]\n",
              "7   #EskomMpumalanga hosted a Supplier Development...  ...                  [#EskomMpumalanga]\n",
              "8   @maxon_hadebe @CityofJoburgZA Please log a cal...  ...                                 NaN\n",
              "9   @Magudulela_M Hi,  Please log a call on MyEsko...  ...                                 NaN\n",
              "10  RT @Exposcience: #FridayThoughts Norman Mashir...  ...                   [#FridayThoughts]\n",
              "\n",
              "[11 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}